# üöÄ Complete Model Improvement Execution Guide

## üìã **EXECUTION ORDER FOR FULL DATASET EXPERIMENT**

Follow this exact order to run the complete model improvement pipeline on the full dataset:

### **Phase 1: Data Preparation & Prerequisites** ‚è±Ô∏è ~30 minutes

#### 1. **Install Dependencies**
```bash
pip install optuna optuna-integration[keras] plotly scikit-optimize
```

#### 2. **Verify Data Files**
```bash
python -c "import pandas as pd; print('‚úì data_path.csv:', len(pd.read_csv('data_path.csv'))); print('‚úì features.csv:', pd.read_csv('features.csv').shape)"
```

#### 3. **Run Baseline Test (Optional but Recommended)**
```bash
python original_test.py
```
- **Purpose**: Establish baseline performance
- **Output**: Original model accuracy (~70%)
- **Runtime**: ~2 minutes

---

### **Phase 2: Enhanced Feature Creation** ‚è±Ô∏è ~2-4 hours

#### 4. **Create Enhanced Features (CRITICAL)**
```bash
python advanced_data_augmentation.py
```
- **Purpose**: Generate augmented dataset with advanced audio processing
- **Output**: `enhanced_features.csv` (6x larger dataset)
- **Runtime**: 2-4 hours for full dataset
- **‚ö†Ô∏è WARNING**: This is the longest step - do NOT interrupt!

---

### **Phase 3: Hyperparameter Optimization** ‚è±Ô∏è ~2-3 hours

#### 5. **Run Optuna Optimization**
```bash
python optuna_hyperparameter_tuning.py
```
- **Purpose**: Find optimal hyperparameters using advanced search
- **Output**: `optuna_best_emotion_model.h5`, `optuna_study.pkl`, `optuna_trials.csv`
- **Runtime**: 2-3 hours (50+ trials)
- **Can be interrupted**: Progress is saved automatically

---

### **Phase 4: Advanced Architecture Training** ‚è±Ô∏è ~4-6 hours

#### 6. **Train Advanced Models**
```bash
python advanced_models.py
```
- **Purpose**: Train state-of-the-art architectures (ResNet, Attention, Transformer)
- **Output**: Multiple `.h5` model files
- **Runtime**: 4-6 hours for all architectures
- **Memory**: Requires 8GB+ RAM

---

### **Phase 5: Advanced Training Techniques** ‚è±Ô∏è ~2-3 hours

#### 7. **Apply Advanced Training**
```bash
python advanced_training_techniques.py
```
- **Purpose**: Apply MixUp, Label Smoothing, Advanced Regularization
- **Output**: Improved model performance metrics
- **Runtime**: 2-3 hours

---

### **Phase 6: Comprehensive Evaluation** ‚è±Ô∏è ~30 minutes

#### 8. **Run Complete Comparison**
```bash
python baseline_comparison.py
```
- **Purpose**: Compare all methods comprehensively
- **Output**: Detailed performance comparison
- **Runtime**: 30 minutes

#### 9. **Generate Final Results**
```bash
python final_results_summary.py
```
- **Purpose**: Generate comprehensive report
- **Output**: `IMPROVEMENT_REPORT.txt`
- **Runtime**: <1 minute

---

## üìä **EXPECTED TIMELINE (Full Dataset)**

| Phase | Script | Time | Cumulative |
|-------|--------|------|------------|
| 1 | Prerequisites | 30min | 30min |
| 2 | Data Augmentation | 3hrs | 3.5hrs |
| 3 | Optuna Optimization | 2.5hrs | 6hrs |
| 4 | Advanced Models | 5hrs | 11hrs |
| 5 | Training Techniques | 2.5hrs | 13.5hrs |
| 6 | Evaluation | 30min | 14hrs |

**Total Estimated Time: 12-16 hours**

---

## ‚öôÔ∏è **SYSTEM REQUIREMENTS**

### **Minimum Requirements:**
- **RAM**: 8GB (16GB recommended)
- **Storage**: 5GB free space
- **CPU**: 4+ cores
- **GPU**: Optional but recommended (significant speedup)

### **Recommended Setup:**
- **RAM**: 16GB+
- **GPU**: CUDA-compatible (GTX 1060+ or RTX series)
- **Storage**: SSD with 10GB+ free space

---

## üõ°Ô∏è **CRITICAL SAFETY MEASURES**

### **Before Starting:**
1. **Backup your data**:
```bash
cp features.csv features_backup.csv
cp data_path.csv data_path_backup.csv
```

2. **Check disk space**:
```bash
df -h .
```

3. **Monitor system resources**:
```bash
htop  # Keep running in another terminal
```

### **During Execution:**
- **Never interrupt Phase 2** (data augmentation) - corruption risk
- **Monitor disk space** - augmented dataset can be large
- **Save progress** - each script saves intermediate results
- **Check logs** for errors or warnings

---

## üîÑ **RECOVERY PROCEDURES**

### **If a Script Fails:**

#### **Data Augmentation Failed:**
```bash
# Check what was created
ls -la enhanced_features.csv
# If partial file exists, delete and restart
rm enhanced_features.csv
python advanced_data_augmentation.py
```

#### **Optuna Optimization Failed:**
```bash
# Check saved study
ls -la optuna_study.pkl
# Resume from checkpoint (automatic)
python optuna_hyperparameter_tuning.py
```

#### **Model Training Failed:**
```bash
# Check for saved models
ls -la *.h5
# Individual models are saved, can continue from where it failed
```

---

## üìà **MONITORING PROGRESS**

### **Real-time Monitoring:**
```bash
# Terminal 1: Run the script
python advanced_data_augmentation.py

# Terminal 2: Monitor progress
watch -n 5 'ls -lh enhanced_features.csv 2>/dev/null || echo "File not created yet"'

# Terminal 3: Monitor system resources
htop
```

### **Check Progress Files:**
```bash
# Check intermediate outputs
ls -la *.csv *.h5 *.pkl
```

---

## üéØ **EXPECTED RESULTS**

### **Performance Targets:**
- **Baseline**: ~70% accuracy
- **After Enhancement**: 75-85% accuracy
- **Best Case**: 85-90% accuracy

### **Output Files:**
- `enhanced_features.csv` - Augmented dataset
- `optuna_best_emotion_model.h5` - Best hyperparameter model
- `best_*_model.h5` - Advanced architecture models  
- `IMPROVEMENT_REPORT.txt` - Comprehensive results
- `optuna_trials.csv` - Hyperparameter search results

---

## üö® **TROUBLESHOOTING**

### **Common Issues:**

#### **Out of Memory:**
```bash
# Reduce batch size in scripts
# Edit the files and change batch_size=64 to batch_size=32 or 16
```

#### **CUDA/GPU Issues:**
```bash
# Force CPU-only mode
export CUDA_VISIBLE_DEVICES=""
python script_name.py
```

#### **Library Issues:**
```bash
pip install --upgrade tensorflow keras librosa optuna
```

#### **Disk Space Full:**
```bash
# Clean up intermediate files
rm quick_*.csv quick_*.h5
# Check space
du -sh .
```

---

## ‚úÖ **FINAL CHECKLIST**

Before starting the full experiment:
- [ ] All dependencies installed
- [ ] At least 10GB free disk space  
- [ ] Backup important files
- [ ] System monitoring setup
- [ ] Expected 12-16 hour runtime confirmed
- [ ] Stable power supply (laptop plugged in)

**Ready to run? Start with Step 1! üöÄ**

---

## üìû **Success Validation**

After completion, you should have:
- [ ] `enhanced_features.csv` > 100MB
- [ ] `optuna_best_emotion_model.h5` exists
- [ ] `IMPROVEMENT_REPORT.txt` with results > 70% accuracy
- [ ] Multiple `.h5` model files
- [ ] Performance improvement of 5-15 percentage points

**If any of these are missing, refer to the Recovery Procedures section.**